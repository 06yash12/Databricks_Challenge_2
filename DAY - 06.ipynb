{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a4eaa6b1-4243-4ba5-b334-a2e08aa0a4f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "# Load bronze events table\n",
    "events = spark.table(\"workspace.ecommerce.events_delta\")\n",
    "# Recreate binary label\n",
    "label_df = events.groupBy(\"user_id\").agg(\n",
    "    F.max(\n",
    "        F.when(F.col(\"event_type\") == \"purchase\", 1).otherwise(0)\n",
    "    ).alias(\"purchased\"))\n",
    "# Load silver feature table\n",
    "features_df = spark.table(\"workspace.ecommerce.user_features_silver\")\n",
    "# Recreate training dataset (features + label)\n",
    "training_data = features_df.join(label_df, \"user_id\")\n",
    "print(\"Training dataset recreated successfully!\")\n",
    "training_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d3ad6160-5da8-4d8b-bd1d-a131ef02dd93",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"total_events\", \"purchases\", \"total_spent\", \"avg_price\"],\n",
    "    outputCol=\"features\")\n",
    "ml_data = assembler.transform(training_data).select(\"features\", \"purchased\")\n",
    "print(\"Feature vector created successfully!\")\n",
    "ml_data.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "330ea8db-5f1f-4086-a88f-565b8c1ee00e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"purchased\",\n",
    "    maxIter=20,\n",
    "    regParam=0.1)\n",
    "lr_model = lr.fit(ml_data)\n",
    "print(\"Logistic Regression model trained successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bec3f57c-c4ad-4915-a159-369911fde0b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "lr_predictions = lr_model.transform(ml_data) # Generate predictions from Logistic Regression model\n",
    "evaluator = BinaryClassificationEvaluator(  # Evaluate using AUC\n",
    "    labelCol=\"purchased\",\n",
    "    rawPredictionCol=\"rawPrediction\",\n",
    "    metricName=\"areaUnderROC\")\n",
    "lr_auc = evaluator.evaluate(lr_predictions)\n",
    "print(\"Logistic Regression AUC:\", lr_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29ec0bc7-324e-4dd9-b633-acfd737d5f6c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "rf = RandomForestClassifier(\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"purchased\",\n",
    "    numTrees=100,\n",
    "    maxDepth=5,\n",
    "    seed=42)\n",
    "rf_model = rf.fit(ml_data)\n",
    "print(\"Random Forest model trained successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6cdeb9e7-a65a-4f6b-a502-a08eb846b963",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Generate predictions from RandomForest model\n",
    "rf_predictions = rf_model.transform(ml_data)\n",
    "# Evaluate AUC for RandomForest\n",
    "rf_auc = evaluator.evaluate(rf_predictions)\n",
    "print(\"RandomForest AUC:\", rf_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b455731-3ca5-437f-8817-1dd8fbedbd1b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Recreate train/test split from training_data\n",
    "train_df, test_df = training_data.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "print(\"Train/Test recreated successfully!\")\n",
    "print(\"Train count:\", train_df.count())\n",
    "print(\"Test count:\", test_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "975d7f1f-086d-405d-93b5-fe3e24077ea4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create ML-ready train dataset\n",
    "train_ml = assembler.transform(train_df) \\\n",
    ".select(\"features\", F.col(\"purchased\").alias(\"label\"))\n",
    "\n",
    "# Create ML-ready test dataset\n",
    "test_ml = assembler.transform(test_df) \\\n",
    ".select(\"features\", F.col(\"purchased\").alias(\"label\"))\n",
    "\n",
    "print(\"Train and Test ML datasets prepared!\")\n",
    "print(\"Train ML count:\", train_ml.count())\n",
    "print(\"Test ML count:\", test_ml.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5bb2c5c5-c4b6-4567-85e6-70babe66cecd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# Train model\n",
    "lr_final = LogisticRegression(\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"label\",\n",
    "    maxIter=20,\n",
    "    regParam=0.1\n",
    ")\n",
    "\n",
    "lr_final_model = lr_final.fit(train_ml)\n",
    "\n",
    "print(\"Final Logistic Regression model trained on TRAIN set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f4213f7-056c-495f-8285-8c0ecd992d66",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Make predictions on TEST data\n",
    "lr_test_predictions = lr_final_model.transform(test_ml)\n",
    "\n",
    "# Create evaluator for AUC\n",
    "evaluator = BinaryClassificationEvaluator(\n",
    "    labelCol=\"label\",\n",
    "    rawPredictionCol=\"rawPrediction\",\n",
    "    metricName=\"areaUnderROC\")\n",
    "# Calculate REAL AUC on unseen test data\n",
    "lr_test_auc = evaluator.evaluate(lr_test_predictions)\n",
    "\n",
    "print(\"Final Logistic Regression Test AUC:\", lr_test_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3014b6de-3536-443e-b082-840573dc080f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Retrain RandomForest on TRAIN set (correct way)\n",
    "rf_final = RandomForestClassifier(\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"label\",\n",
    "    numTrees=50,\n",
    "    maxDepth=10,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "rf_final_model = rf_final.fit(train_ml)\n",
    "\n",
    "print(\"Final RandomForest model trained on TRAIN set!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd9f5b07-75d6-452f-be04-69c0edd5b2ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Make predictions on TEST data using final RandomForest model\n",
    "rf_test_predictions = rf_final_model.transform(test_ml)\n",
    "\n",
    "# Calculate REAL AUC on unseen test data\n",
    "rf_test_auc = evaluator.evaluate(rf_test_predictions)\n",
    "\n",
    "print(\"Final RandomForest Test AUC:\", rf_test_auc)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "DAY - 06",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
